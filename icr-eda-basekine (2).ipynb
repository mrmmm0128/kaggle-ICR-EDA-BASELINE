{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.10.10","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle/python Docker image: https://github.com/kaggle/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np\nimport pandas as pd\nimport optuna\nfrom sklearn import datasets, metrics\nfrom sklearn.model_selection import KFold, StratifiedKFold\nfrom sklearn.preprocessing import StandardScaler, MinMaxScaler\nfrom sklearn.ensemble import RandomForestClassifier\nfrom sklearn.svm import SVC\nfrom statistics import mean\n\n# Input data files are available in the read-only \"../input/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('/kaggle/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# You can write up to 20GB to the current directory (/kaggle/working/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to /kaggle/temp/, but they won't be saved outside of the current session","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","execution":{"iopub.status.busy":"2023-05-17T05:43:19.629950Z","iopub.execute_input":"2023-05-17T05:43:19.630428Z","iopub.status.idle":"2023-05-17T05:43:19.643650Z","shell.execute_reply.started":"2023-05-17T05:43:19.630395Z","shell.execute_reply":"2023-05-17T05:43:19.642257Z"},"trusted":true},"execution_count":102,"outputs":[{"name":"stdout","text":"/kaggle/input/icr-identify-age-related-conditions/sample_submission.csv\n/kaggle/input/icr-identify-age-related-conditions/greeks.csv\n/kaggle/input/icr-identify-age-related-conditions/train.csv\n/kaggle/input/icr-identify-age-related-conditions/test.csv\n","output_type":"stream"}]},{"cell_type":"code","source":"train_df=pd.read_csv('/kaggle/input/icr-identify-age-related-conditions/train.csv')\ntest_df=pd.read_csv('/kaggle/input/icr-identify-age-related-conditions/test.csv')\ngreeks_df=pd.read_csv('/kaggle/input/icr-identify-age-related-conditions/greeks.csv')\ntest_Id=test_df[\"Id\"]","metadata":{"execution":{"iopub.status.busy":"2023-05-17T05:43:20.181424Z","iopub.execute_input":"2023-05-17T05:43:20.182050Z","iopub.status.idle":"2023-05-17T05:43:20.207634Z","shell.execute_reply.started":"2023-05-17T05:43:20.182010Z","shell.execute_reply":"2023-05-17T05:43:20.206797Z"},"trusted":true},"execution_count":103,"outputs":[]},{"cell_type":"code","source":"from sklearn.model_selection import KFold,StratifiedKFold,train_test_split,GridSearchCV\nfrom sklearn.metrics import roc_auc_score,accuracy_score,confusion_matrix,ConfusionMatrixDisplay,RocCurveDisplay\n\nimport time \nfrom xgboost import XGBClassifier\nfrom sklearn.metrics import log_loss","metadata":{"execution":{"iopub.status.busy":"2023-05-17T05:43:21.082285Z","iopub.execute_input":"2023-05-17T05:43:21.083061Z","iopub.status.idle":"2023-05-17T05:43:21.087663Z","shell.execute_reply.started":"2023-05-17T05:43:21.083026Z","shell.execute_reply":"2023-05-17T05:43:21.086765Z"},"trusted":true},"execution_count":104,"outputs":[]},{"cell_type":"code","source":"train_df.head()","metadata":{"execution":{"iopub.status.busy":"2023-05-17T05:43:21.516174Z","iopub.execute_input":"2023-05-17T05:43:21.516860Z","iopub.status.idle":"2023-05-17T05:43:21.540827Z","shell.execute_reply.started":"2023-05-17T05:43:21.516818Z","shell.execute_reply":"2023-05-17T05:43:21.539734Z"},"trusted":true},"execution_count":105,"outputs":[{"execution_count":105,"output_type":"execute_result","data":{"text/plain":"             Id        AB          AF          AH         AM        AR  \\\n0  000ff2bfdfe9  0.209377  3109.03329   85.200147  22.394407  8.138688   \n1  007255e47698  0.145282   978.76416   85.200147  36.968889  8.138688   \n2  013f2bd269f5  0.470030  2635.10654   85.200147  32.360553  8.138688   \n3  043ac50845d5  0.252107  3819.65177  120.201618  77.112203  8.138688   \n4  044fb8a146ec  0.380297  3733.04844   85.200147  14.103738  8.138688   \n\n         AX        AY         AZ          BC  ...        FL        FR  \\\n0  0.699861  0.025578   9.812214    5.555634  ...  7.298162   1.73855   \n1  3.632190  0.025578  13.517790    1.229900  ...  0.173229   0.49706   \n2  6.732840  0.025578  12.824570    1.229900  ...  7.709560   0.97556   \n3  3.685344  0.025578  11.053708    1.229900  ...  6.122162   0.49706   \n4  3.942255  0.054810   3.396778  102.151980  ...  8.153058  48.50134   \n\n         FS         GB          GE            GF         GH         GI  \\\n0  0.094822  11.339138   72.611063   2003.810319  22.136229  69.834944   \n1  0.568932   9.292698   72.611063  27981.562750  29.135430  32.131996   \n2  1.198821  37.077772   88.609437  13676.957810  28.022851  35.192676   \n3  0.284466  18.529584   82.416803   2094.262452  39.948656  90.493248   \n4  0.121914  16.408728  146.109943   8524.370502  45.381316  36.262628   \n\n          GL  Class  \n0   0.120343      1  \n1  21.978000      0  \n2   0.196941      0  \n3   0.155829      0  \n4   0.096614      1  \n\n[5 rows x 58 columns]","text/html":"<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>Id</th>\n      <th>AB</th>\n      <th>AF</th>\n      <th>AH</th>\n      <th>AM</th>\n      <th>AR</th>\n      <th>AX</th>\n      <th>AY</th>\n      <th>AZ</th>\n      <th>BC</th>\n      <th>...</th>\n      <th>FL</th>\n      <th>FR</th>\n      <th>FS</th>\n      <th>GB</th>\n      <th>GE</th>\n      <th>GF</th>\n      <th>GH</th>\n      <th>GI</th>\n      <th>GL</th>\n      <th>Class</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>000ff2bfdfe9</td>\n      <td>0.209377</td>\n      <td>3109.03329</td>\n      <td>85.200147</td>\n      <td>22.394407</td>\n      <td>8.138688</td>\n      <td>0.699861</td>\n      <td>0.025578</td>\n      <td>9.812214</td>\n      <td>5.555634</td>\n      <td>...</td>\n      <td>7.298162</td>\n      <td>1.73855</td>\n      <td>0.094822</td>\n      <td>11.339138</td>\n      <td>72.611063</td>\n      <td>2003.810319</td>\n      <td>22.136229</td>\n      <td>69.834944</td>\n      <td>0.120343</td>\n      <td>1</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>007255e47698</td>\n      <td>0.145282</td>\n      <td>978.76416</td>\n      <td>85.200147</td>\n      <td>36.968889</td>\n      <td>8.138688</td>\n      <td>3.632190</td>\n      <td>0.025578</td>\n      <td>13.517790</td>\n      <td>1.229900</td>\n      <td>...</td>\n      <td>0.173229</td>\n      <td>0.49706</td>\n      <td>0.568932</td>\n      <td>9.292698</td>\n      <td>72.611063</td>\n      <td>27981.562750</td>\n      <td>29.135430</td>\n      <td>32.131996</td>\n      <td>21.978000</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>013f2bd269f5</td>\n      <td>0.470030</td>\n      <td>2635.10654</td>\n      <td>85.200147</td>\n      <td>32.360553</td>\n      <td>8.138688</td>\n      <td>6.732840</td>\n      <td>0.025578</td>\n      <td>12.824570</td>\n      <td>1.229900</td>\n      <td>...</td>\n      <td>7.709560</td>\n      <td>0.97556</td>\n      <td>1.198821</td>\n      <td>37.077772</td>\n      <td>88.609437</td>\n      <td>13676.957810</td>\n      <td>28.022851</td>\n      <td>35.192676</td>\n      <td>0.196941</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>043ac50845d5</td>\n      <td>0.252107</td>\n      <td>3819.65177</td>\n      <td>120.201618</td>\n      <td>77.112203</td>\n      <td>8.138688</td>\n      <td>3.685344</td>\n      <td>0.025578</td>\n      <td>11.053708</td>\n      <td>1.229900</td>\n      <td>...</td>\n      <td>6.122162</td>\n      <td>0.49706</td>\n      <td>0.284466</td>\n      <td>18.529584</td>\n      <td>82.416803</td>\n      <td>2094.262452</td>\n      <td>39.948656</td>\n      <td>90.493248</td>\n      <td>0.155829</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>044fb8a146ec</td>\n      <td>0.380297</td>\n      <td>3733.04844</td>\n      <td>85.200147</td>\n      <td>14.103738</td>\n      <td>8.138688</td>\n      <td>3.942255</td>\n      <td>0.054810</td>\n      <td>3.396778</td>\n      <td>102.151980</td>\n      <td>...</td>\n      <td>8.153058</td>\n      <td>48.50134</td>\n      <td>0.121914</td>\n      <td>16.408728</td>\n      <td>146.109943</td>\n      <td>8524.370502</td>\n      <td>45.381316</td>\n      <td>36.262628</td>\n      <td>0.096614</td>\n      <td>1</td>\n    </tr>\n  </tbody>\n</table>\n<p>5 rows × 58 columns</p>\n</div>"},"metadata":{}}]},{"cell_type":"code","source":"train_df.dtypes","metadata":{"execution":{"iopub.status.busy":"2023-05-17T05:43:22.012184Z","iopub.execute_input":"2023-05-17T05:43:22.012603Z","iopub.status.idle":"2023-05-17T05:43:22.021621Z","shell.execute_reply.started":"2023-05-17T05:43:22.012571Z","shell.execute_reply":"2023-05-17T05:43:22.020488Z"},"trusted":true},"execution_count":106,"outputs":[{"execution_count":106,"output_type":"execute_result","data":{"text/plain":"Id        object\nAB       float64\nAF       float64\nAH       float64\nAM       float64\nAR       float64\nAX       float64\nAY       float64\nAZ       float64\nBC       float64\nBD       float64\nBN       float64\nBP       float64\nBQ       float64\nBR       float64\nBZ       float64\nCB       float64\nCC       float64\nCD       float64\nCF       float64\nCH       float64\nCL       float64\nCR       float64\nCS       float64\nCU       float64\nCW       float64\nDA       float64\nDE       float64\nDF       float64\nDH       float64\nDI       float64\nDL       float64\nDN       float64\nDU       float64\nDV       float64\nDY       float64\nEB       float64\nEE       float64\nEG       float64\nEH       float64\nEJ        object\nEL       float64\nEP       float64\nEU       float64\nFC       float64\nFD       float64\nFE       float64\nFI       float64\nFL       float64\nFR       float64\nFS       float64\nGB       float64\nGE       float64\nGF       float64\nGH       float64\nGI       float64\nGL       float64\nClass      int64\ndtype: object"},"metadata":{}}]},{"cell_type":"code","source":"test_df.dtypes","metadata":{"execution":{"iopub.status.busy":"2023-05-17T05:43:22.378898Z","iopub.execute_input":"2023-05-17T05:43:22.380037Z","iopub.status.idle":"2023-05-17T05:43:22.388245Z","shell.execute_reply.started":"2023-05-17T05:43:22.379994Z","shell.execute_reply":"2023-05-17T05:43:22.387470Z"},"trusted":true},"execution_count":107,"outputs":[{"execution_count":107,"output_type":"execute_result","data":{"text/plain":"Id      object\nAB     float64\nAF     float64\nAH     float64\nAM     float64\nAR     float64\nAX     float64\nAY     float64\nAZ     float64\nBC     float64\nBD     float64\nBN     float64\nBP     float64\nBQ     float64\nBR     float64\nBZ     float64\nCB     float64\nCC     float64\nCD     float64\nCF     float64\nCH     float64\nCL     float64\nCR     float64\nCS     float64\nCU     float64\nCW     float64\nDA     float64\nDE     float64\nDF     float64\nDH     float64\nDI     float64\nDL     float64\nDN     float64\nDU     float64\nDV     float64\nDY     float64\nEB     float64\nEE     float64\nEG     float64\nEH     float64\nEJ      object\nEL     float64\nEP     float64\nEU     float64\nFC     float64\nFD     float64\nFE     float64\nFI     float64\nFL     float64\nFR     float64\nFS     float64\nGB     float64\nGE     float64\nGF     float64\nGH     float64\nGI     float64\nGL     float64\ndtype: object"},"metadata":{}}]},{"cell_type":"code","source":"num_cols = train_df.select_dtypes(include=[\"float64\"]).columns.tolist()\ncat_cols = train_df.select_dtypes(include=[\"object\"]).columns.tolist()\ncat_cols.remove(\"Id\")","metadata":{"execution":{"iopub.status.busy":"2023-05-17T05:43:22.741511Z","iopub.execute_input":"2023-05-17T05:43:22.742696Z","iopub.status.idle":"2023-05-17T05:43:22.748534Z","shell.execute_reply.started":"2023-05-17T05:43:22.742656Z","shell.execute_reply":"2023-05-17T05:43:22.747505Z"},"trusted":true},"execution_count":108,"outputs":[]},{"cell_type":"code","source":"total_row_train=train_df.shape\ntotal_row_test=test_df.shape\ntype(total_row_train[0])","metadata":{"execution":{"iopub.status.busy":"2023-05-17T05:43:23.159303Z","iopub.execute_input":"2023-05-17T05:43:23.159712Z","iopub.status.idle":"2023-05-17T05:43:23.166454Z","shell.execute_reply.started":"2023-05-17T05:43:23.159679Z","shell.execute_reply":"2023-05-17T05:43:23.165258Z"},"trusted":true},"execution_count":109,"outputs":[{"execution_count":109,"output_type":"execute_result","data":{"text/plain":"int"},"metadata":{}}]},{"cell_type":"code","source":"num=len(train_df[train_df[\"Class\"]==1])\npercentage=num/(total_row_train[0])*100\nprint(f\"there are {num} Classes are '1', which is {percentage:.2f}% total training dataset.\")\n\nnum=len(train_df[train_df[\"Class\"]==0])\npercentage=num/(total_row_train[0])*100\nprint(f\"there are {num} Classes are '0', which is {percentage:.2f}% total training dataset.\")\n","metadata":{"execution":{"iopub.status.busy":"2023-05-17T05:43:23.518755Z","iopub.execute_input":"2023-05-17T05:43:23.519709Z","iopub.status.idle":"2023-05-17T05:43:23.528902Z","shell.execute_reply.started":"2023-05-17T05:43:23.519673Z","shell.execute_reply":"2023-05-17T05:43:23.527848Z"},"trusted":true},"execution_count":110,"outputs":[{"name":"stdout","text":"there are 108 Classes are '1', which is 17.50% total training dataset.\nthere are 509 Classes are '0', which is 82.50% total training dataset.\n","output_type":"stream"}]},{"cell_type":"code","source":"train_df.isnull().sum().loc[train_df.isnull().sum()>0]","metadata":{"execution":{"iopub.status.busy":"2023-05-17T05:43:23.867423Z","iopub.execute_input":"2023-05-17T05:43:23.867854Z","iopub.status.idle":"2023-05-17T05:43:23.881343Z","shell.execute_reply.started":"2023-05-17T05:43:23.867821Z","shell.execute_reply":"2023-05-17T05:43:23.880140Z"},"trusted":true},"execution_count":111,"outputs":[{"execution_count":111,"output_type":"execute_result","data":{"text/plain":"BQ    60\nCB     2\nCC     3\nDU     1\nEL    60\nFC     1\nFL     1\nFS     2\nGL     1\ndtype: int64"},"metadata":{}}]},{"cell_type":"code","source":"test_df.isnull().sum().loc[train_df.isnull().sum()>0]","metadata":{"execution":{"iopub.status.busy":"2023-05-17T05:43:24.245687Z","iopub.execute_input":"2023-05-17T05:43:24.246120Z","iopub.status.idle":"2023-05-17T05:43:24.259254Z","shell.execute_reply.started":"2023-05-17T05:43:24.246088Z","shell.execute_reply":"2023-05-17T05:43:24.258150Z"},"trusted":true},"execution_count":112,"outputs":[{"execution_count":112,"output_type":"execute_result","data":{"text/plain":"BQ    0\nCB    0\nCC    0\nDU    0\nEL    0\nFC    0\nFL    0\nFS    0\nGL    0\ndtype: int64"},"metadata":{}}]},{"cell_type":"code","source":"train_df.describe()","metadata":{"execution":{"iopub.status.busy":"2023-05-17T05:43:24.607598Z","iopub.execute_input":"2023-05-17T05:43:24.608178Z","iopub.status.idle":"2023-05-17T05:43:24.751129Z","shell.execute_reply.started":"2023-05-17T05:43:24.608142Z","shell.execute_reply":"2023-05-17T05:43:24.749993Z"},"trusted":true},"execution_count":113,"outputs":[{"execution_count":113,"output_type":"execute_result","data":{"text/plain":"               AB            AF           AH          AM          AR  \\\ncount  617.000000    617.000000   617.000000  617.000000  617.000000   \nmean     0.477149   3502.013221   118.624513   38.968552   10.128242   \nstd      0.468388   2300.322717   127.838950   69.728226   10.518877   \nmin      0.081187    192.593280    85.200147    3.177522    8.138688   \n25%      0.252107   2197.345480    85.200147   12.270314    8.138688   \n50%      0.354659   3120.318960    85.200147   20.533110    8.138688   \n75%      0.559763   4361.637390   113.739540   39.139886    8.138688   \nmax      6.161666  28688.187660  1910.123198  630.518230  178.943634   \n\n               AX          AY          AZ           BC           BD   ...  \\\ncount  617.000000  617.000000  617.000000   617.000000    617.000000  ...   \nmean     5.545576    0.060320   10.566447     8.053012   5350.388655  ...   \nstd      2.551696    0.416817    4.350645    65.166943   3021.326641  ...   \nmin      0.699861    0.025578    3.396778     1.229900   1693.624320  ...   \n25%      4.128294    0.025578    8.129580     1.229900   4155.702870  ...   \n50%      5.031912    0.025578   10.461320     1.229900   4997.960730  ...   \n75%      6.431634    0.036845   12.969516     5.081244   6035.885700  ...   \nmax     38.270880   10.315851   38.971568  1463.693448  53060.599240  ...   \n\n               FL           FR          FS          GB           GE  \\\ncount  616.000000   617.000000  615.000000  617.000000   617.000000   \nmean     5.433199     3.533905    0.421501   20.724856   131.714987   \nstd     11.496257    50.181948    1.305365    9.991907   144.181524   \nmin      0.173229     0.497060    0.067730    4.102182    72.611063   \n25%      0.173229     0.497060    0.067730   14.036718    72.611063   \n50%      3.028141     1.131000    0.250601   18.771436    72.611063   \n75%      6.238814     1.512060    0.535067   25.608406   127.591671   \nmax    137.932739  1244.227020   31.365763  135.781294  1497.351958   \n\n                  GF          GH          GI          GL       Class  \ncount     617.000000  617.000000  617.000000  616.000000  617.000000  \nmean    14679.595398   31.489716   50.584437    8.530961    0.175041  \nstd     19352.959387    9.864239   36.266251   10.327010    0.380310  \nmin        13.038894    9.432735    0.897628    0.001129    0.000000  \n25%      2798.992584   25.034888   23.011684    0.124392    0.000000  \n50%      7838.273610   30.608946   41.007968    0.337827    0.000000  \n75%     19035.709240   36.863947   67.931664   21.978000    0.000000  \nmax    143790.071200   81.210825  191.194764   21.978000    1.000000  \n\n[8 rows x 56 columns]","text/html":"<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>AB</th>\n      <th>AF</th>\n      <th>AH</th>\n      <th>AM</th>\n      <th>AR</th>\n      <th>AX</th>\n      <th>AY</th>\n      <th>AZ</th>\n      <th>BC</th>\n      <th>BD</th>\n      <th>...</th>\n      <th>FL</th>\n      <th>FR</th>\n      <th>FS</th>\n      <th>GB</th>\n      <th>GE</th>\n      <th>GF</th>\n      <th>GH</th>\n      <th>GI</th>\n      <th>GL</th>\n      <th>Class</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>count</th>\n      <td>617.000000</td>\n      <td>617.000000</td>\n      <td>617.000000</td>\n      <td>617.000000</td>\n      <td>617.000000</td>\n      <td>617.000000</td>\n      <td>617.000000</td>\n      <td>617.000000</td>\n      <td>617.000000</td>\n      <td>617.000000</td>\n      <td>...</td>\n      <td>616.000000</td>\n      <td>617.000000</td>\n      <td>615.000000</td>\n      <td>617.000000</td>\n      <td>617.000000</td>\n      <td>617.000000</td>\n      <td>617.000000</td>\n      <td>617.000000</td>\n      <td>616.000000</td>\n      <td>617.000000</td>\n    </tr>\n    <tr>\n      <th>mean</th>\n      <td>0.477149</td>\n      <td>3502.013221</td>\n      <td>118.624513</td>\n      <td>38.968552</td>\n      <td>10.128242</td>\n      <td>5.545576</td>\n      <td>0.060320</td>\n      <td>10.566447</td>\n      <td>8.053012</td>\n      <td>5350.388655</td>\n      <td>...</td>\n      <td>5.433199</td>\n      <td>3.533905</td>\n      <td>0.421501</td>\n      <td>20.724856</td>\n      <td>131.714987</td>\n      <td>14679.595398</td>\n      <td>31.489716</td>\n      <td>50.584437</td>\n      <td>8.530961</td>\n      <td>0.175041</td>\n    </tr>\n    <tr>\n      <th>std</th>\n      <td>0.468388</td>\n      <td>2300.322717</td>\n      <td>127.838950</td>\n      <td>69.728226</td>\n      <td>10.518877</td>\n      <td>2.551696</td>\n      <td>0.416817</td>\n      <td>4.350645</td>\n      <td>65.166943</td>\n      <td>3021.326641</td>\n      <td>...</td>\n      <td>11.496257</td>\n      <td>50.181948</td>\n      <td>1.305365</td>\n      <td>9.991907</td>\n      <td>144.181524</td>\n      <td>19352.959387</td>\n      <td>9.864239</td>\n      <td>36.266251</td>\n      <td>10.327010</td>\n      <td>0.380310</td>\n    </tr>\n    <tr>\n      <th>min</th>\n      <td>0.081187</td>\n      <td>192.593280</td>\n      <td>85.200147</td>\n      <td>3.177522</td>\n      <td>8.138688</td>\n      <td>0.699861</td>\n      <td>0.025578</td>\n      <td>3.396778</td>\n      <td>1.229900</td>\n      <td>1693.624320</td>\n      <td>...</td>\n      <td>0.173229</td>\n      <td>0.497060</td>\n      <td>0.067730</td>\n      <td>4.102182</td>\n      <td>72.611063</td>\n      <td>13.038894</td>\n      <td>9.432735</td>\n      <td>0.897628</td>\n      <td>0.001129</td>\n      <td>0.000000</td>\n    </tr>\n    <tr>\n      <th>25%</th>\n      <td>0.252107</td>\n      <td>2197.345480</td>\n      <td>85.200147</td>\n      <td>12.270314</td>\n      <td>8.138688</td>\n      <td>4.128294</td>\n      <td>0.025578</td>\n      <td>8.129580</td>\n      <td>1.229900</td>\n      <td>4155.702870</td>\n      <td>...</td>\n      <td>0.173229</td>\n      <td>0.497060</td>\n      <td>0.067730</td>\n      <td>14.036718</td>\n      <td>72.611063</td>\n      <td>2798.992584</td>\n      <td>25.034888</td>\n      <td>23.011684</td>\n      <td>0.124392</td>\n      <td>0.000000</td>\n    </tr>\n    <tr>\n      <th>50%</th>\n      <td>0.354659</td>\n      <td>3120.318960</td>\n      <td>85.200147</td>\n      <td>20.533110</td>\n      <td>8.138688</td>\n      <td>5.031912</td>\n      <td>0.025578</td>\n      <td>10.461320</td>\n      <td>1.229900</td>\n      <td>4997.960730</td>\n      <td>...</td>\n      <td>3.028141</td>\n      <td>1.131000</td>\n      <td>0.250601</td>\n      <td>18.771436</td>\n      <td>72.611063</td>\n      <td>7838.273610</td>\n      <td>30.608946</td>\n      <td>41.007968</td>\n      <td>0.337827</td>\n      <td>0.000000</td>\n    </tr>\n    <tr>\n      <th>75%</th>\n      <td>0.559763</td>\n      <td>4361.637390</td>\n      <td>113.739540</td>\n      <td>39.139886</td>\n      <td>8.138688</td>\n      <td>6.431634</td>\n      <td>0.036845</td>\n      <td>12.969516</td>\n      <td>5.081244</td>\n      <td>6035.885700</td>\n      <td>...</td>\n      <td>6.238814</td>\n      <td>1.512060</td>\n      <td>0.535067</td>\n      <td>25.608406</td>\n      <td>127.591671</td>\n      <td>19035.709240</td>\n      <td>36.863947</td>\n      <td>67.931664</td>\n      <td>21.978000</td>\n      <td>0.000000</td>\n    </tr>\n    <tr>\n      <th>max</th>\n      <td>6.161666</td>\n      <td>28688.187660</td>\n      <td>1910.123198</td>\n      <td>630.518230</td>\n      <td>178.943634</td>\n      <td>38.270880</td>\n      <td>10.315851</td>\n      <td>38.971568</td>\n      <td>1463.693448</td>\n      <td>53060.599240</td>\n      <td>...</td>\n      <td>137.932739</td>\n      <td>1244.227020</td>\n      <td>31.365763</td>\n      <td>135.781294</td>\n      <td>1497.351958</td>\n      <td>143790.071200</td>\n      <td>81.210825</td>\n      <td>191.194764</td>\n      <td>21.978000</td>\n      <td>1.000000</td>\n    </tr>\n  </tbody>\n</table>\n<p>8 rows × 56 columns</p>\n</div>"},"metadata":{}}]},{"cell_type":"code","source":"from sklearn.impute import SimpleImputer\nfrom sklearn.preprocessing import MinMaxScaler,OneHotEncoder\nfrom sklearn.utils import class_weight\nfrom sklearn.metrics import accuracy_score\n\nimputer=SimpleImputer(strategy=\"mean\")\nnumeric_df=pd.DataFrame(imputer.fit_transform(train_df[num_cols]),columns=num_cols\n                )\n\nscaler=MinMaxScaler()\nscaled_numeric_df=pd.DataFrame(scaler.fit_transform(numeric_df),columns=num_cols)\n\nencoder=OneHotEncoder(sparse_output=False,handle_unknown=\"ignore\")\nencoded_cat_df=pd.DataFrame(encoder.fit_transform(train_df[cat_cols]),columns=encoder.get_feature_names_out(cat_cols))\n\nprocessed_df=pd.concat([scaled_numeric_df,encoded_cat_df],axis=1)","metadata":{"execution":{"iopub.status.busy":"2023-05-17T05:43:24.983610Z","iopub.execute_input":"2023-05-17T05:43:24.984642Z","iopub.status.idle":"2023-05-17T05:43:25.005338Z","shell.execute_reply.started":"2023-05-17T05:43:24.984604Z","shell.execute_reply":"2023-05-17T05:43:25.004500Z"},"trusted":true},"execution_count":114,"outputs":[]},{"cell_type":"code","source":"\nclass Classifier:\n    def __init__(self,params):\n        self.params=params\n        if params[\"standardize\"]==\"StandardScaler\":\n            self.standardizer=StandardScaler()\n        elif params[\"standardize\"]==\"MinMaxScaler\":\n            self.standardizer=MinMaxScaler()\n        elif params[\"standardize\"]==\"Noscaler\" :\n            self.standardizer=Noscaler()\n        \n        if params[\"classifier_name\"]==\"RandomForest\":\n            self.classifier=RandomForestClassifier(**params[\"classifier_params\"])\n        elif params[\"classifier_name\"]==\"XGB\":\n            self.classifier=XGBClassifier(**params[\"classifier_params\"])\n    \n    def _fit_and_predict_core(self,x,y=None,fitting=False,proba=False):\n        if fitting==True:\n            self.standardizer.fit(x)\n        self.standardizer.transform(x)\n        \n        if fitting==True:\n            self.classifier.fit(x,y)\n        \n        if y is None:\n            if proba:\n                return self.classifier.predict_proba(x)\n            else:\n                return self.classifier.predict(x)\n        return None\n    \n    def fit(self,x,y):\n        self._fit_and_predict_core(x,y,fitting=True)\n        return self\n    \n    def predict(self,x):\n        pred_y=self._fit_and_predict_core(x)\n        return pred_y\n    \n    def predict_proba(self,x):\n        pred_y=self._fit_and_predict_core(x,proba=True)\n        return pred_y\n            ","metadata":{"execution":{"iopub.status.busy":"2023-05-17T05:43:25.322863Z","iopub.execute_input":"2023-05-17T05:43:25.324001Z","iopub.status.idle":"2023-05-17T05:43:25.334073Z","shell.execute_reply.started":"2023-05-17T05:43:25.323952Z","shell.execute_reply":"2023-05-17T05:43:25.332901Z"},"trusted":true},"execution_count":115,"outputs":[]},{"cell_type":"code","source":"class Objective:\n    def __init__(self,x,y,label_index):\n        self.x=x\n        self.y=y\n        self.label_index=label_index\n        self.best_score=0\n        self.best_params=None\n    \n    def __call__(self,trial):\n        x=self.x\n        y=self.y\n        params=self.generate_params(trial,x)\n        \n        classifier=Classifier(params)\n        \n        skf=StratifiedKFold(n_splits=5,random_state=2019,shuffle=True)\n        \n        acc=[]\n        \n        for train,test in skf.split(x,y):\n            train_y=y.iloc[train].values\n            test_y=y.iloc[test].values\n            train_x=x.iloc[train].values\n            test_x=x.iloc[test].values\n            \n            classifier.fit(train_x,train_y)\n            pred_y=classifier.predict(test_x).reshape(-1).astype(np.int)\n            \n        \n            acc.append(metrics.accuracy_score(test_y,pred_y))\n        \n        f1_score=mean(acc)\n        if self.best_score<f1_score:\n            self.best_score-f1_score\n            self.best_params=params\n        return f1_score\n    def generate_params(self,trial,x):\n        params={}\n        \n        params[\"standardize\"]=trial.suggest_categorical(\"standardize\",[\"StandardScaler\",\"MinMaxScaler\"])\n        params[\"classifier_name\"]=trial.suggest_categorical(\"classifier_name\",[\"RandomForest\",\"XGB\"])\n        classifier_params={}\n        if params[\"classifier_name\"]==\"RandomForest\":\n            classifier_params['n_estimators'] = trial.suggest_categorical(\n                'rf_n_estimators', [5, 10, 20, 30, 50, 100])\n            classifier_params['max_features'] = trial.suggest_categorical(\n                'rf_max_features', [\"auto\", 0.2, 0.4, 0.6, 0.8])\n            \n            classifier_params['n_jobs'] = -1\n        elif params[\"classifier_name\"]==\"XGB\":\n            classifier_params[\"x_estimators\"]=trial.suggest_categorical(\"rf_x_estimators\",[100,300,500,700,1000])\n            classifier_params[\"max_depth\"]=trial.suggest_categorical(\"rf_max_depth\",[3,4,5,6,7])\n            \n        else:\n            raise RuntimeError('unspport classifier', params['classifier_name'])\n            \n        params[\"classifier_params\"]=classifier_params \n        return params","metadata":{"execution":{"iopub.status.busy":"2023-05-17T05:43:25.651858Z","iopub.execute_input":"2023-05-17T05:43:25.652278Z","iopub.status.idle":"2023-05-17T05:43:25.665146Z","shell.execute_reply.started":"2023-05-17T05:43:25.652246Z","shell.execute_reply":"2023-05-17T05:43:25.663989Z"},"trusted":true},"execution_count":116,"outputs":[]},{"cell_type":"code","source":"x=np.linspace(0,616,617)\nx=list(x)\nW=train_df[\"Class\"].values\nlabel,label_index=pd.factorize(W)\nlabel_index","metadata":{"execution":{"iopub.status.busy":"2023-05-17T05:43:26.018843Z","iopub.execute_input":"2023-05-17T05:43:26.019861Z","iopub.status.idle":"2023-05-17T05:43:26.028773Z","shell.execute_reply.started":"2023-05-17T05:43:26.019818Z","shell.execute_reply":"2023-05-17T05:43:26.027753Z"},"trusted":true},"execution_count":117,"outputs":[{"execution_count":117,"output_type":"execute_result","data":{"text/plain":"array([1, 0])"},"metadata":{}}]},{"cell_type":"code","source":"import optuna\nlabel_index=train_df.index.tolist\nobjective = Objective(x=processed_df, y=train_df[\"Class\"], label_index=label_index)\nstudy = optuna.create_study(direction='maximize')\nparam2=study.optimize(objective, n_trials=5)","metadata":{"execution":{"iopub.status.busy":"2023-05-17T05:43:26.386384Z","iopub.execute_input":"2023-05-17T05:43:26.387051Z","iopub.status.idle":"2023-05-17T05:43:29.223370Z","shell.execute_reply.started":"2023-05-17T05:43:26.387018Z","shell.execute_reply":"2023-05-17T05:43:29.222270Z"},"trusted":true},"execution_count":118,"outputs":[{"name":"stderr","text":"\u001b[32m[I 2023-05-17 05:43:26,389]\u001b[0m A new study created in memory with name: no-name-51b3b384-527c-43f4-a0f3-0afd7771c732\u001b[0m\n/opt/conda/lib/python3.10/site-packages/sklearn/ensemble/_forest.py:424: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features='sqrt'` or remove this parameter as it is also the default value for RandomForestClassifiers and ExtraTreesClassifiers.\n  warn(\n/tmp/ipykernel_35/1707216753.py:27: DeprecationWarning: `np.int` is a deprecated alias for the builtin `int`. To silence this warning, use `int` by itself. Doing this will not modify any behavior and is safe. When replacing `np.int`, you may wish to use e.g. `np.int64` or `np.int32` to specify the precision. If you wish to review your current use, check the release note link for additional information.\nDeprecated in NumPy 1.20; for more details and guidance: https://numpy.org/devdocs/release/1.20.0-notes.html#deprecations\n  pred_y=classifier.predict(test_x).reshape(-1).astype(np.int)\n/opt/conda/lib/python3.10/site-packages/sklearn/ensemble/_forest.py:424: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features='sqrt'` or remove this parameter as it is also the default value for RandomForestClassifiers and ExtraTreesClassifiers.\n  warn(\n/tmp/ipykernel_35/1707216753.py:27: DeprecationWarning: `np.int` is a deprecated alias for the builtin `int`. To silence this warning, use `int` by itself. Doing this will not modify any behavior and is safe. When replacing `np.int`, you may wish to use e.g. `np.int64` or `np.int32` to specify the precision. If you wish to review your current use, check the release note link for additional information.\nDeprecated in NumPy 1.20; for more details and guidance: https://numpy.org/devdocs/release/1.20.0-notes.html#deprecations\n  pred_y=classifier.predict(test_x).reshape(-1).astype(np.int)\n/opt/conda/lib/python3.10/site-packages/sklearn/ensemble/_forest.py:424: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features='sqrt'` or remove this parameter as it is also the default value for RandomForestClassifiers and ExtraTreesClassifiers.\n  warn(\n/tmp/ipykernel_35/1707216753.py:27: DeprecationWarning: `np.int` is a deprecated alias for the builtin `int`. To silence this warning, use `int` by itself. Doing this will not modify any behavior and is safe. When replacing `np.int`, you may wish to use e.g. `np.int64` or `np.int32` to specify the precision. If you wish to review your current use, check the release note link for additional information.\nDeprecated in NumPy 1.20; for more details and guidance: https://numpy.org/devdocs/release/1.20.0-notes.html#deprecations\n  pred_y=classifier.predict(test_x).reshape(-1).astype(np.int)\n/opt/conda/lib/python3.10/site-packages/sklearn/ensemble/_forest.py:424: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features='sqrt'` or remove this parameter as it is also the default value for RandomForestClassifiers and ExtraTreesClassifiers.\n  warn(\n/tmp/ipykernel_35/1707216753.py:27: DeprecationWarning: `np.int` is a deprecated alias for the builtin `int`. To silence this warning, use `int` by itself. Doing this will not modify any behavior and is safe. When replacing `np.int`, you may wish to use e.g. `np.int64` or `np.int32` to specify the precision. If you wish to review your current use, check the release note link for additional information.\nDeprecated in NumPy 1.20; for more details and guidance: https://numpy.org/devdocs/release/1.20.0-notes.html#deprecations\n  pred_y=classifier.predict(test_x).reshape(-1).astype(np.int)\n/opt/conda/lib/python3.10/site-packages/sklearn/ensemble/_forest.py:424: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features='sqrt'` or remove this parameter as it is also the default value for RandomForestClassifiers and ExtraTreesClassifiers.\n  warn(\n/tmp/ipykernel_35/1707216753.py:27: DeprecationWarning: `np.int` is a deprecated alias for the builtin `int`. To silence this warning, use `int` by itself. Doing this will not modify any behavior and is safe. When replacing `np.int`, you may wish to use e.g. `np.int64` or `np.int32` to specify the precision. If you wish to review your current use, check the release note link for additional information.\nDeprecated in NumPy 1.20; for more details and guidance: https://numpy.org/devdocs/release/1.20.0-notes.html#deprecations\n  pred_y=classifier.predict(test_x).reshape(-1).astype(np.int)\n\u001b[32m[I 2023-05-17 05:43:26,783]\u001b[0m Trial 0 finished with value: 0.9092315761867296 and parameters: {'standardize': 'StandardScaler', 'classifier_name': 'RandomForest', 'rf_n_estimators': 20, 'rf_max_features': 'auto'}. Best is trial 0 with value: 0.9092315761867296.\u001b[0m\n/tmp/ipykernel_35/1707216753.py:27: DeprecationWarning: `np.int` is a deprecated alias for the builtin `int`. To silence this warning, use `int` by itself. Doing this will not modify any behavior and is safe. When replacing `np.int`, you may wish to use e.g. `np.int64` or `np.int32` to specify the precision. If you wish to review your current use, check the release note link for additional information.\nDeprecated in NumPy 1.20; for more details and guidance: https://numpy.org/devdocs/release/1.20.0-notes.html#deprecations\n  pred_y=classifier.predict(test_x).reshape(-1).astype(np.int)\n/tmp/ipykernel_35/1707216753.py:27: DeprecationWarning: `np.int` is a deprecated alias for the builtin `int`. To silence this warning, use `int` by itself. Doing this will not modify any behavior and is safe. When replacing `np.int`, you may wish to use e.g. `np.int64` or `np.int32` to specify the precision. If you wish to review your current use, check the release note link for additional information.\nDeprecated in NumPy 1.20; for more details and guidance: https://numpy.org/devdocs/release/1.20.0-notes.html#deprecations\n  pred_y=classifier.predict(test_x).reshape(-1).astype(np.int)\n/tmp/ipykernel_35/1707216753.py:27: DeprecationWarning: `np.int` is a deprecated alias for the builtin `int`. To silence this warning, use `int` by itself. Doing this will not modify any behavior and is safe. When replacing `np.int`, you may wish to use e.g. `np.int64` or `np.int32` to specify the precision. If you wish to review your current use, check the release note link for additional information.\nDeprecated in NumPy 1.20; for more details and guidance: https://numpy.org/devdocs/release/1.20.0-notes.html#deprecations\n  pred_y=classifier.predict(test_x).reshape(-1).astype(np.int)\n/tmp/ipykernel_35/1707216753.py:27: DeprecationWarning: `np.int` is a deprecated alias for the builtin `int`. To silence this warning, use `int` by itself. Doing this will not modify any behavior and is safe. When replacing `np.int`, you may wish to use e.g. `np.int64` or `np.int32` to specify the precision. If you wish to review your current use, check the release note link for additional information.\nDeprecated in NumPy 1.20; for more details and guidance: https://numpy.org/devdocs/release/1.20.0-notes.html#deprecations\n  pred_y=classifier.predict(test_x).reshape(-1).astype(np.int)\n/tmp/ipykernel_35/1707216753.py:27: DeprecationWarning: `np.int` is a deprecated alias for the builtin `int`. To silence this warning, use `int` by itself. Doing this will not modify any behavior and is safe. When replacing `np.int`, you may wish to use e.g. `np.int64` or `np.int32` to specify the precision. If you wish to review your current use, check the release note link for additional information.\nDeprecated in NumPy 1.20; for more details and guidance: https://numpy.org/devdocs/release/1.20.0-notes.html#deprecations\n  pred_y=classifier.predict(test_x).reshape(-1).astype(np.int)\n\u001b[32m[I 2023-05-17 05:43:27,478]\u001b[0m Trial 1 finished with value: 0.9125360608444794 and parameters: {'standardize': 'MinMaxScaler', 'classifier_name': 'RandomForest', 'rf_n_estimators': 30, 'rf_max_features': 0.4}. Best is trial 1 with value: 0.9125360608444794.\u001b[0m\n/tmp/ipykernel_35/1707216753.py:27: DeprecationWarning: `np.int` is a deprecated alias for the builtin `int`. To silence this warning, use `int` by itself. Doing this will not modify any behavior and is safe. When replacing `np.int`, you may wish to use e.g. `np.int64` or `np.int32` to specify the precision. If you wish to review your current use, check the release note link for additional information.\nDeprecated in NumPy 1.20; for more details and guidance: https://numpy.org/devdocs/release/1.20.0-notes.html#deprecations\n  pred_y=classifier.predict(test_x).reshape(-1).astype(np.int)\n","output_type":"stream"},{"name":"stdout","text":"[05:43:27] WARNING: ../src/learner.cc:767: \nParameters: { \"x_estimators\" } are not used.\n\n[05:43:27] WARNING: ../src/learner.cc:767: \nParameters: { \"x_estimators\" } are not used.\n\n","output_type":"stream"},{"name":"stderr","text":"/tmp/ipykernel_35/1707216753.py:27: DeprecationWarning: `np.int` is a deprecated alias for the builtin `int`. To silence this warning, use `int` by itself. Doing this will not modify any behavior and is safe. When replacing `np.int`, you may wish to use e.g. `np.int64` or `np.int32` to specify the precision. If you wish to review your current use, check the release note link for additional information.\nDeprecated in NumPy 1.20; for more details and guidance: https://numpy.org/devdocs/release/1.20.0-notes.html#deprecations\n  pred_y=classifier.predict(test_x).reshape(-1).astype(np.int)\n/tmp/ipykernel_35/1707216753.py:27: DeprecationWarning: `np.int` is a deprecated alias for the builtin `int`. To silence this warning, use `int` by itself. Doing this will not modify any behavior and is safe. When replacing `np.int`, you may wish to use e.g. `np.int64` or `np.int32` to specify the precision. If you wish to review your current use, check the release note link for additional information.\nDeprecated in NumPy 1.20; for more details and guidance: https://numpy.org/devdocs/release/1.20.0-notes.html#deprecations\n  pred_y=classifier.predict(test_x).reshape(-1).astype(np.int)\n","output_type":"stream"},{"name":"stdout","text":"[05:43:27] WARNING: ../src/learner.cc:767: \nParameters: { \"x_estimators\" } are not used.\n\n[05:43:27] WARNING: ../src/learner.cc:767: \nParameters: { \"x_estimators\" } are not used.\n\n","output_type":"stream"},{"name":"stderr","text":"/tmp/ipykernel_35/1707216753.py:27: DeprecationWarning: `np.int` is a deprecated alias for the builtin `int`. To silence this warning, use `int` by itself. Doing this will not modify any behavior and is safe. When replacing `np.int`, you may wish to use e.g. `np.int64` or `np.int32` to specify the precision. If you wish to review your current use, check the release note link for additional information.\nDeprecated in NumPy 1.20; for more details and guidance: https://numpy.org/devdocs/release/1.20.0-notes.html#deprecations\n  pred_y=classifier.predict(test_x).reshape(-1).astype(np.int)\n/tmp/ipykernel_35/1707216753.py:27: DeprecationWarning: `np.int` is a deprecated alias for the builtin `int`. To silence this warning, use `int` by itself. Doing this will not modify any behavior and is safe. When replacing `np.int`, you may wish to use e.g. `np.int64` or `np.int32` to specify the precision. If you wish to review your current use, check the release note link for additional information.\nDeprecated in NumPy 1.20; for more details and guidance: https://numpy.org/devdocs/release/1.20.0-notes.html#deprecations\n  pred_y=classifier.predict(test_x).reshape(-1).astype(np.int)\n\u001b[32m[I 2023-05-17 05:43:28,117]\u001b[0m Trial 2 finished with value: 0.9319564647259375 and parameters: {'standardize': 'StandardScaler', 'classifier_name': 'XGB', 'rf_x_estimators': 100, 'rf_max_depth': 6}. Best is trial 2 with value: 0.9319564647259375.\u001b[0m\n","output_type":"stream"},{"name":"stdout","text":"[05:43:27] WARNING: ../src/learner.cc:767: \nParameters: { \"x_estimators\" } are not used.\n\n[05:43:28] WARNING: ../src/learner.cc:767: \nParameters: { \"x_estimators\" } are not used.\n\n","output_type":"stream"},{"name":"stderr","text":"/tmp/ipykernel_35/1707216753.py:27: DeprecationWarning: `np.int` is a deprecated alias for the builtin `int`. To silence this warning, use `int` by itself. Doing this will not modify any behavior and is safe. When replacing `np.int`, you may wish to use e.g. `np.int64` or `np.int32` to specify the precision. If you wish to review your current use, check the release note link for additional information.\nDeprecated in NumPy 1.20; for more details and guidance: https://numpy.org/devdocs/release/1.20.0-notes.html#deprecations\n  pred_y=classifier.predict(test_x).reshape(-1).astype(np.int)\n/tmp/ipykernel_35/1707216753.py:27: DeprecationWarning: `np.int` is a deprecated alias for the builtin `int`. To silence this warning, use `int` by itself. Doing this will not modify any behavior and is safe. When replacing `np.int`, you may wish to use e.g. `np.int64` or `np.int32` to specify the precision. If you wish to review your current use, check the release note link for additional information.\nDeprecated in NumPy 1.20; for more details and guidance: https://numpy.org/devdocs/release/1.20.0-notes.html#deprecations\n  pred_y=classifier.predict(test_x).reshape(-1).astype(np.int)\n","output_type":"stream"},{"name":"stdout","text":"[05:43:28] WARNING: ../src/learner.cc:767: \nParameters: { \"x_estimators\" } are not used.\n\n[05:43:28] WARNING: ../src/learner.cc:767: \nParameters: { \"x_estimators\" } are not used.\n\n","output_type":"stream"},{"name":"stderr","text":"/tmp/ipykernel_35/1707216753.py:27: DeprecationWarning: `np.int` is a deprecated alias for the builtin `int`. To silence this warning, use `int` by itself. Doing this will not modify any behavior and is safe. When replacing `np.int`, you may wish to use e.g. `np.int64` or `np.int32` to specify the precision. If you wish to review your current use, check the release note link for additional information.\nDeprecated in NumPy 1.20; for more details and guidance: https://numpy.org/devdocs/release/1.20.0-notes.html#deprecations\n  pred_y=classifier.predict(test_x).reshape(-1).astype(np.int)\n/tmp/ipykernel_35/1707216753.py:27: DeprecationWarning: `np.int` is a deprecated alias for the builtin `int`. To silence this warning, use `int` by itself. Doing this will not modify any behavior and is safe. When replacing `np.int`, you may wish to use e.g. `np.int64` or `np.int32` to specify the precision. If you wish to review your current use, check the release note link for additional information.\nDeprecated in NumPy 1.20; for more details and guidance: https://numpy.org/devdocs/release/1.20.0-notes.html#deprecations\n  pred_y=classifier.predict(test_x).reshape(-1).astype(np.int)\n","output_type":"stream"},{"name":"stdout","text":"[05:43:28] WARNING: ../src/learner.cc:767: \nParameters: { \"x_estimators\" } are not used.\n\n[05:43:28] WARNING: ../src/learner.cc:767: \nParameters: { \"x_estimators\" } are not used.\n\n","output_type":"stream"},{"name":"stderr","text":"/tmp/ipykernel_35/1707216753.py:27: DeprecationWarning: `np.int` is a deprecated alias for the builtin `int`. To silence this warning, use `int` by itself. Doing this will not modify any behavior and is safe. When replacing `np.int`, you may wish to use e.g. `np.int64` or `np.int32` to specify the precision. If you wish to review your current use, check the release note link for additional information.\nDeprecated in NumPy 1.20; for more details and guidance: https://numpy.org/devdocs/release/1.20.0-notes.html#deprecations\n  pred_y=classifier.predict(test_x).reshape(-1).astype(np.int)\n\u001b[32m[I 2023-05-17 05:43:28,692]\u001b[0m Trial 3 finished with value: 0.9271308680828744 and parameters: {'standardize': 'StandardScaler', 'classifier_name': 'XGB', 'rf_x_estimators': 300, 'rf_max_depth': 3}. Best is trial 2 with value: 0.9319564647259375.\u001b[0m\n/tmp/ipykernel_35/1707216753.py:27: DeprecationWarning: `np.int` is a deprecated alias for the builtin `int`. To silence this warning, use `int` by itself. Doing this will not modify any behavior and is safe. When replacing `np.int`, you may wish to use e.g. `np.int64` or `np.int32` to specify the precision. If you wish to review your current use, check the release note link for additional information.\nDeprecated in NumPy 1.20; for more details and guidance: https://numpy.org/devdocs/release/1.20.0-notes.html#deprecations\n  pred_y=classifier.predict(test_x).reshape(-1).astype(np.int)\n/tmp/ipykernel_35/1707216753.py:27: DeprecationWarning: `np.int` is a deprecated alias for the builtin `int`. To silence this warning, use `int` by itself. Doing this will not modify any behavior and is safe. When replacing `np.int`, you may wish to use e.g. `np.int64` or `np.int32` to specify the precision. If you wish to review your current use, check the release note link for additional information.\nDeprecated in NumPy 1.20; for more details and guidance: https://numpy.org/devdocs/release/1.20.0-notes.html#deprecations\n  pred_y=classifier.predict(test_x).reshape(-1).astype(np.int)\n/tmp/ipykernel_35/1707216753.py:27: DeprecationWarning: `np.int` is a deprecated alias for the builtin `int`. To silence this warning, use `int` by itself. Doing this will not modify any behavior and is safe. When replacing `np.int`, you may wish to use e.g. `np.int64` or `np.int32` to specify the precision. If you wish to review your current use, check the release note link for additional information.\nDeprecated in NumPy 1.20; for more details and guidance: https://numpy.org/devdocs/release/1.20.0-notes.html#deprecations\n  pred_y=classifier.predict(test_x).reshape(-1).astype(np.int)\n/tmp/ipykernel_35/1707216753.py:27: DeprecationWarning: `np.int` is a deprecated alias for the builtin `int`. To silence this warning, use `int` by itself. Doing this will not modify any behavior and is safe. When replacing `np.int`, you may wish to use e.g. `np.int64` or `np.int32` to specify the precision. If you wish to review your current use, check the release note link for additional information.\nDeprecated in NumPy 1.20; for more details and guidance: https://numpy.org/devdocs/release/1.20.0-notes.html#deprecations\n  pred_y=classifier.predict(test_x).reshape(-1).astype(np.int)\n/tmp/ipykernel_35/1707216753.py:27: DeprecationWarning: `np.int` is a deprecated alias for the builtin `int`. To silence this warning, use `int` by itself. Doing this will not modify any behavior and is safe. When replacing `np.int`, you may wish to use e.g. `np.int64` or `np.int32` to specify the precision. If you wish to review your current use, check the release note link for additional information.\nDeprecated in NumPy 1.20; for more details and guidance: https://numpy.org/devdocs/release/1.20.0-notes.html#deprecations\n  pred_y=classifier.predict(test_x).reshape(-1).astype(np.int)\n\u001b[32m[I 2023-05-17 05:43:29,219]\u001b[0m Trial 4 finished with value: 0.8947285601888277 and parameters: {'standardize': 'MinMaxScaler', 'classifier_name': 'RandomForest', 'rf_n_estimators': 20, 'rf_max_features': 0.6}. Best is trial 2 with value: 0.9319564647259375.\u001b[0m\n","output_type":"stream"}]},{"cell_type":"code","source":"FOLDS=10\nSEED=1004\nX=processed_df\ny=train_df[\"Class\"]\nweights=class_weight.compute_sample_weight(\"balanced\",y)\nskf=StratifiedKFold(n_splits=FOLDS,shuffle=True,random_state=SEED)\nfor fold,(train_idx,val_idx) in enumerate(skf.split(X,y)):\n    X_train,y_train=X.iloc[train_idx],y.iloc[train_idx]\n    X_valid,y_valid=X.iloc[val_idx],y.iloc[val_idx]\n    watchlist=[(X_train,y_train),(X_valid,y_valid)]\n    \n    model=XGBClassifier(x_estimators=300,max_depth=3)\n    model.fit(X_train,y_train,sample_weight=weights[train_idx],eval_set=watchlist,early_stopping_rounds=300,verbose=0)","metadata":{"execution":{"iopub.status.busy":"2023-05-17T05:43:46.948468Z","iopub.execute_input":"2023-05-17T05:43:46.949780Z","iopub.status.idle":"2023-05-17T05:43:49.315301Z","shell.execute_reply.started":"2023-05-17T05:43:46.949729Z","shell.execute_reply":"2023-05-17T05:43:49.314343Z"},"trusted":true},"execution_count":119,"outputs":[{"name":"stderr","text":"/opt/conda/lib/python3.10/site-packages/xgboost/sklearn.py:835: UserWarning: `early_stopping_rounds` in `fit` method is deprecated for better compatibility with scikit-learn, use `early_stopping_rounds` in constructor or`set_params` instead.\n  warnings.warn(\n","output_type":"stream"},{"name":"stdout","text":"[05:43:46] WARNING: ../src/learner.cc:767: \nParameters: { \"x_estimators\" } are not used.\n\n[05:43:47] WARNING: ../src/learner.cc:767: \nParameters: { \"x_estimators\" } are not used.\n\n[05:43:47] WARNING: ../src/learner.cc:767: \nParameters: { \"x_estimators\" } are not used.\n\n[05:43:47] WARNING: ../src/learner.cc:767: \nParameters: { \"x_estimators\" } are not used.\n\n[05:43:47] WARNING: ../src/learner.cc:767: \nParameters: { \"x_estimators\" } are not used.\n\n[05:43:48] WARNING: ../src/learner.cc:767: \nParameters: { \"x_estimators\" } are not used.\n\n[05:43:48] WARNING: ../src/learner.cc:767: \nParameters: { \"x_estimators\" } are not used.\n\n[05:43:48] WARNING: ../src/learner.cc:767: \nParameters: { \"x_estimators\" } are not used.\n\n[05:43:48] WARNING: ../src/learner.cc:767: \nParameters: { \"x_estimators\" } are not used.\n\n[05:43:49] WARNING: ../src/learner.cc:767: \nParameters: { \"x_estimators\" } are not used.\n\n","output_type":"stream"}]},{"cell_type":"code","source":"model=RandomForestClassifier(n_estimators=20,random_state=0,max_features=0.2)\nskf=StratifiedKFold(n_splits=5,random_state=2019,shuffle=True)\nfor train,test in skf.split(processed_df,train_df[\"Class\"]):\n            train_y=train_df[\"Class\"].iloc[train].values\n            test_y=train_df[\"Class\"].iloc[test].values\n            train_x=processed_df.iloc[train].values\n            test_x=processed_df.iloc[test].values\n            \n            model.fit(train_x,train_y)","metadata":{"execution":{"iopub.status.busy":"2023-05-17T05:46:45.287895Z","iopub.execute_input":"2023-05-17T05:46:45.288402Z","iopub.status.idle":"2023-05-17T05:46:45.741591Z","shell.execute_reply.started":"2023-05-17T05:46:45.288368Z","shell.execute_reply":"2023-05-17T05:46:45.740314Z"},"trusted":true},"execution_count":120,"outputs":[]},{"cell_type":"code","source":"test_df=test_df.drop([\"Id\"],axis=1)","metadata":{"execution":{"iopub.status.busy":"2023-05-17T05:46:47.967333Z","iopub.execute_input":"2023-05-17T05:46:47.967749Z","iopub.status.idle":"2023-05-17T05:46:47.974368Z","shell.execute_reply.started":"2023-05-17T05:46:47.967717Z","shell.execute_reply":"2023-05-17T05:46:47.973205Z"},"trusted":true},"execution_count":121,"outputs":[]},{"cell_type":"code","source":"test_df[\"EJ_A\"]=0\ntest_df[\"EJ_B\"]=0","metadata":{"execution":{"iopub.status.busy":"2023-05-17T05:46:48.391353Z","iopub.execute_input":"2023-05-17T05:46:48.392052Z","iopub.status.idle":"2023-05-17T05:46:48.399170Z","shell.execute_reply.started":"2023-05-17T05:46:48.392006Z","shell.execute_reply":"2023-05-17T05:46:48.398101Z"},"trusted":true},"execution_count":122,"outputs":[]},{"cell_type":"code","source":"test_df[\"EJ_A\"][test_df[\"EJ\"]==\"A\"]=1\ntest_df[\"EJ_B\"][test_df[\"EJ\"]==\"B\"]=1","metadata":{"execution":{"iopub.status.busy":"2023-05-17T05:46:50.454223Z","iopub.execute_input":"2023-05-17T05:46:50.454616Z","iopub.status.idle":"2023-05-17T05:46:50.463553Z","shell.execute_reply.started":"2023-05-17T05:46:50.454587Z","shell.execute_reply":"2023-05-17T05:46:50.462721Z"},"trusted":true},"execution_count":123,"outputs":[{"name":"stderr","text":"/tmp/ipykernel_35/441707066.py:1: SettingWithCopyWarning: \nA value is trying to be set on a copy of a slice from a DataFrame\n\nSee the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n  test_df[\"EJ_A\"][test_df[\"EJ\"]==\"A\"]=1\n/tmp/ipykernel_35/441707066.py:2: SettingWithCopyWarning: \nA value is trying to be set on a copy of a slice from a DataFrame\n\nSee the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n  test_df[\"EJ_B\"][test_df[\"EJ\"]==\"B\"]=1\n","output_type":"stream"}]},{"cell_type":"code","source":"test_df=test_df.drop([\"EJ\"],axis=1)","metadata":{"execution":{"iopub.status.busy":"2023-05-17T05:46:51.723359Z","iopub.execute_input":"2023-05-17T05:46:51.724441Z","iopub.status.idle":"2023-05-17T05:46:51.730113Z","shell.execute_reply.started":"2023-05-17T05:46:51.724403Z","shell.execute_reply":"2023-05-17T05:46:51.729002Z"},"trusted":true},"execution_count":124,"outputs":[]},{"cell_type":"code","source":"pred_df=pd.DataFrame(model.predict_proba(test_df),columns=[\"class_0\",\"class_1\"])","metadata":{"execution":{"iopub.status.busy":"2023-05-17T05:34:05.904686Z","iopub.execute_input":"2023-05-17T05:34:05.905563Z","iopub.status.idle":"2023-05-17T05:34:05.920513Z","shell.execute_reply.started":"2023-05-17T05:34:05.905522Z","shell.execute_reply":"2023-05-17T05:34:05.918732Z"},"trusted":true},"execution_count":99,"outputs":[]},{"cell_type":"code","source":"submission_df = pd.concat([test_Id,pred_df],axis=1)\nsubmission_df.to_csv('submission.csv', index=False)","metadata":{"execution":{"iopub.status.busy":"2023-05-17T05:34:07.593606Z","iopub.execute_input":"2023-05-17T05:34:07.594023Z","iopub.status.idle":"2023-05-17T05:34:07.602324Z","shell.execute_reply.started":"2023-05-17T05:34:07.593992Z","shell.execute_reply":"2023-05-17T05:34:07.601036Z"},"trusted":true},"execution_count":100,"outputs":[]},{"cell_type":"code","source":"submission_df","metadata":{"execution":{"iopub.status.busy":"2023-05-17T05:34:10.517962Z","iopub.execute_input":"2023-05-17T05:34:10.518987Z","iopub.status.idle":"2023-05-17T05:34:10.532828Z","shell.execute_reply.started":"2023-05-17T05:34:10.518943Z","shell.execute_reply":"2023-05-17T05:34:10.531616Z"},"trusted":true},"execution_count":101,"outputs":[{"execution_count":101,"output_type":"execute_result","data":{"text/plain":"             Id   class_0   class_1\n0  00eed32682bb  0.764387  0.235613\n1  010ebe33f668  0.764387  0.235613\n2  02fa521e1838  0.764387  0.235613\n3  040e15f562a2  0.764387  0.235613\n4  046e85c7cc7f  0.764387  0.235613","text/html":"<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>Id</th>\n      <th>class_0</th>\n      <th>class_1</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>00eed32682bb</td>\n      <td>0.764387</td>\n      <td>0.235613</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>010ebe33f668</td>\n      <td>0.764387</td>\n      <td>0.235613</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>02fa521e1838</td>\n      <td>0.764387</td>\n      <td>0.235613</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>040e15f562a2</td>\n      <td>0.764387</td>\n      <td>0.235613</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>046e85c7cc7f</td>\n      <td>0.764387</td>\n      <td>0.235613</td>\n    </tr>\n  </tbody>\n</table>\n</div>"},"metadata":{}}]},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]}]}